---
title: "Bacteria Drying "
subtitle: "NCSU ST 542 Consulting Project"
author: "Bruce Campbell"
latex_engine: xelatex
fontsize: 12pt
output: pdf_document
bibliography: BacteriaDrying-ConsultingProject-WeekOf-041518.bib
---

---
```{r setup, include=FALSE,echo=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(dev = 'pdf')
knitr::opts_chunk$set(cache=TRUE)
knitr::opts_chunk$set(tidy=TRUE)
knitr::opts_chunk$set(prompt=FALSE)
knitr::opts_chunk$set(fig.height=5)
knitr::opts_chunk$set(fig.width=7)
knitr::opts_chunk$set(warning=FALSE)
knitr::opts_chunk$set(message=FALSE)
knitr::opts_knit$set(root.dir = ".")
library(latex2exp)   
library(pander)
library(ggplot2)
library(GGally)

```

## Bacteria Drying

Scientists study bacteria for a variety of reasons.  Bacteria have been the source of great human suffering and more recently it has become known that bacteria are also an important part of human health.  In addition to matters of human health and disease, scientists study bacteria as forms of alternative energy and bio-remediation.  The ability to store bacteria for long periods of time is an important research objective. Scientists need to be able to keep libraries of bacteria to compare bacterial populations over time and to share bacteria among colleagues.  For alternative energy purposes, if bacteria can reliably be dried and re-hydrated then growth plants do not have to be collocated with productions plants.  This has the potential to effectively make bacteria a stored energy source.  For bio-remediation if bacteria can be reliably re-hydrated on site then deployment becomes easier as storing and transporting the bacteria in a dehydrated state is more cost effective.   

This study aims to evaluate a variety of bacterial drying methodologies to determine optimal conditions for re-hydration.  The specific aim is to have mechanism capable of producing ethanol/acetate at rates higher than 20% of undried bacteria.  Variables used in the drying process include the addition of chemicals, different mechanisms for removal of oxygen, and different storage conditions.   Samples from the same bacterial population are exposed to different drying mechanisms, are re-hydrated, and then measured for anaerobic respiration.  The population surviving the drying process is measured through the amount of carbon monoxide produced after re-hydration.  Increasing numbers of bacteria that survive the drying process lead to decreasing carbon monoxide levels.  Since this measurement is the sum of many small contributions we expect the response to be normally distributed. The overall goals are to find the conditions which minimize the carbon monoxide levels - thus providing optimal conditions for bacteria re-hydration. 

##Methods 

### Method introduction

The bacteria drying experiments are carried out carefully in a traditional biological laboratory.  Bacteria are grown in culture media prior to the experiments and samples from the same media are used in the different experiments for drying and storage.  After storage bacteria are re-hydrated in individual tubes which are first evacuated with argon and then infused with hydrogen and carbon dioxide to enable respiration. Treatments are grouped into experiments and carried out by different individuals.  There are two phases to the experiment - a drying phase and a re-hydration phase. The treatment could be present in the drying phase or the re-hydration phase. The design is both qualitative and quantitative in the treatments applied. 

Vacuum exposure is known to cause damage to bacteria cell membranes and that there is a repair mechanism for eliminating the damage[@PMID:12180476].  This study noted that the damage can be repaired after storage when the temperature is raised. It's also know that freeze-drying can cause genetic injuries in bacteria with the number of mutations increasing with the length of the storage time [@ASHWOODSMITH1980205].  These are just some of the underlying factors that the experiments will be implicitly measuring.

Detailed notes are included with the experiments indicating any anomalies in them, and describing the lab procedures and materials used.  Bacteria are grown from 7 cultures which are used in the experiments. Each sample is a unit of a cell formulation which is dried, stored, and then re-hydrated. Media is spun in a Beckman, and then rinsed with 20 mL from 25 mL bottle of 1YCM PCG  with 1 mL Cys and 0.2 M NaOH. After that the sample is tube centrifuged in rotana for 15min at 4C and 6000rcf.  After drying tubes are tubes flushed with argon at 20 psi for 25 minutes and then stored.  

An experiment generally contains 10-25 formulations. In all there are 43 experiments with 775 samples.  73 samples have missing responses which are redacted from the analysis.  The measures for this study are the experiment ID's which encode the conditions for the experiment and response conditions of the outcome.  The responses are measures of cellular respiration; H2,O2,N2,CO	CO2.

### Statistical Analysis

We will be investigating several approaches to analyzing this data. The first step will be to implement a 1 way ANOVA on the experiment and treatment.  This will determine if the mean responses of the experiment are different. The model we use is that the repose $y_{ij}$ of replicate $i$ in the $j$ is expressed as 
${\displaystyle y_{i,j}=\mu +\tau _{j}+\varepsilon _{i,j}}$ where ${\displaystyle i=1,\dotsc ,I}$ an index over the replicates ${\displaystyle j=1,\dotsc ,J}$ is the index over experiments, ${\displaystyle \mu _{j}}$ is the mean of the CO measurements for experiment $j$,${\displaystyle \mu }$ is the overall mean CO, and $\tau_j$ is the treatment effect for experiment $j$ - a deviation from the overall mean.  The errors $\epsilon_{i \;j} \sim N(0,\sigma^2)$ are normally distributed with equal variance.

In order to validate the assumption that the group variances are the same we perform a Levene test and  a Brown and Forsythe Test for equality of variances.  The Levene test uses spread from the mean to check for variances while the Brown-Forsythe uses deviation from the median. ANOVA is generally considered robust to violations to the assumptions of constant variance. A Welch test can be used when this assumption is violated.  Welch's Heteroscedastic F test is a generalization to the Welch-t test to more than 2 groups. For large samples it amounts to a $\chi^2$ test. See [@WelchTest] for more details. 

The response is assumed to be normal but we perform a non parametric Kruskal-Wallis [@KruskalWallis] one-way analysis of variance by ranks for validation of the one way ANOVA, and as an precursor to selecting the optimal experimental conditions.  The Kruskall-Wallis analysis of variance is an extension of the Mann-Whitney U test to multiple groups. We expect the Kruskal-Wallis result will be consistent with the usual 1 way ANOVA.  

*ote that the Kruskal-Wallis test does not assume that the variances are equal, although you won't be able to interpret a significant result as a simple shift in the medians if the shapes of the distributions differ. the KW test tests for identical distributions and not just for the equality of means.*

The assumption of the Kruskal-Wallis is that all the groups come from identical distributions with common variance.  The null hypothesis is the medians are all the same for the groups. Using the notation above, the hypothesis are 

$$H_0 : P(\mu_j > \mu_k) = \frac{1}{2} \;\; \large{\forall} \;\; j,k \in 1,\dotsc ,J$$

$$H_a : \large \exists \;\;j,k \;\;\in 1,\dotsc ,J  :   P(\mu_j > \mu_k) \neq \frac{1}{2} $$
A significant Kruskal-Wallis test indicates that at least one experimental median stochastically  dominates the others.  We do not know which one.  The common options for determining stochastic order are to perform pairwise Mann-Whitney tests or to perform Dunn's Multiple Comparison Test [@DUNN]. Dunn's test has several technical advantages over running pairwise Mann-Whitney tests.  The main advantages are that it uses the pooled variance estimate from the Kruskal-Wallis test, and that it reuses the average rank scores from the Kruskal-Wallis test.  An alternative to the dunn test is the Tukey Honest Significant Differences test which creates a set of confidence intervals on the difference between factor means using the Studentized range statistic.  

Appendix A [REVISIT] contains a detailed description of the Kruskal-Wallis and Dunn tests. 

The input to the Dunn test is the per group average rank $\bar{R_j} = \frac{R_j}{n_j}$ and the z-test statistic for groups $j,k$ is 

$$z_{j,k} = \frac{\bar{R_j} - \bar{R_k}}{\sigma_{j,k}}$$ 
$\sigma_{j,k}$ is a funtion of the overall, group, and rank tie counts (see appendix A).  The null hypothesis of the group pairwise comparison is that the probability of observing a randomly selected value from the first group that is larger than a randomly selected value from the second groups is one half - $H_0 : P(X_j > X_k) = \frac{1}{2}$. 

The null hypothesis for each pairwise comparison is that the probability of observing a randomly selected value from the first group that is larger than a randomly selected value from the second group equals one half; this null hypothesis corresponds to that of the Wilcoxon-Mann-Whitney rank-sum test. 

The Levene test is inplemented in the R package ```car```.  The R package ```oneswaytest``` is used to perform Welch's heteroscedastic F test.  The Kruskal-Wallis is implemented in R in the ```kruskal.test``` function in the core ```stats``` package.  The Dunn test is implemented in the  ```dunn.test``` package.   R version 3.4.2 (2017-09-28) is used to perform the analysis. 

This document is rendered in R markdown. The code for some of the steps is not displayed in the rendered document,  here but is available in the raw markdown.  The GitHub repository is [https://github.com/brucebcampbell/ncsu-consulting-project!](https://github.com/brucebcampbell/ncsu-consulting-project)
 
## Data Description and Preparation
An excel workbook is kept with the experimental data and other lab notes.  This consists of 63 worksheets which are pre-processed from the lab workbook into a series of files suitable for ingest into an R data frame object. An Excel VBA script is run to extract the individual experiments into csv files and the resulting files were investigated for inclusion in the data analysis.  Not all of the worksheet in the data workbook contain experimental data. After looking at each file - there were 44 experiments eligible for inclusion in the data analysis.  Of these 44 one was determined to not have any response measurements and was redacted from the statistical analysis.  The VBA code for extracing the worksheets is listed in Appendix A

We will see below that there are two experiements with very low replicate counts.  We redact these to try and keep the design as balanced as possible. 
```MVK Drying 41516``` had three replicates and ```MJS long drying 52115``` had 6.  The mean replicate count for the remaining experiments is 17. 

50 data elements were found to have no associated reposnse and these were redacted from the analysis data set. 

#### Create master data frame from experiment files.

```{r, results='hide', message=FALSE, warning=FALSE,echo=FALSE}
setwd("c:/e/brucebcampbell-git/ncsu-consulting-project/")
wd <- getwd()
nwd <- paste(wd,"data/r-load-data/",sep = "/")
setwd(nwd)
file.list <-list.files(nwd)

header.list <- list()
#Inspect the Headers 
for(i in 1:length(file.list))
{
  file.name <- file.list[[i]]
  experiment.name  <- tools::file_path_sans_ext(file.name)
  df <- read.csv(paste(nwd,file.name,sep="/"))
  header.list[[i]] <- names(df)
}

str.list <-list()
for(i in 1:length(header.list))
{
  file.name <- file.list[[i]]
  str.wr <- paste(as.character(c(file.name,header.list[[i]])), collapse=", ")
  str.list[[i]] <- str.wr
}

dfmaster <- data.frame()
for(i in 1:length(file.list))
{
  file.name <- file.list[[i]]
  #experiment.name <- strsplit(as.character(file.name),split = ".")[[2]]
  experiment.name  <- tools::file_path_sans_ext(file.name)
  df <- read.csv(paste(nwd,file.name,sep="/"))
  df$experiment <- rep(experiment.name,nrow(df))
  df$experiment.count <- rep(nrow(df),nrow(df))
  df$experiment.mean <- rep(mean(df$CO,na.rm = TRUE),nrow(df))
  names(df)
  
  if("Formulation.pH" %in% colnames(df))
  {
    cat(file.name)
  } else
  {
    df$Formulation.pH <- NULL
  }
  
  if("Formulation" %in% colnames(df))
  {
    cat(file.name)
  } else
  {
    df$Formulation <- "NA" 
  }
  
  names.to.keep <- c ("experiment","Formulation", "CO", "experiment.count","experiment.mean") 
  
  df.keep <- df[,names.to.keep]
  df.keep$CO <- as.numeric( df.keep$CO)
  #plot(df.keep$CO, main=experiment.name)
  
  sum(is.na(df.keep$CO))
  dfmaster <- rbind(df.keep,dfmaster)
}

dfmaster <- dfmaster[order(dfmaster$experiment.mean,decreasing = TRUE),]
  
dfmaster$labtech <-rep(NA,nrow(dfmaster))
for(i in 1:nrow(dfmaster))
{
  dfmaster[i,]$labtech <- substr(as.character(dfmaster[i,]$experiment),1,3)
}

#redact experiemtns with low counts
library(sqldf)

df.counts <- sqldf("select experiment, count(CO) as count,sum(CO) as sum,avg(CO) as mean from dfmaster group by experiment")

df.counts.redacted <- df.counts[df.counts$experiment!= "MJS long drying 52115" & df.counts$experiment!= "MVK Drying 41516",]

dfmaster <- dfmaster[dfmaster$experiment!= "MJS long drying 52115" & dfmaster$experiment!= "MVK Drying 41516",]
```

\newpage

###Data Plots 

Here we display the reponse data by formulation, and lab technician. We also display the counts per experiment. There is evidence that it might be a good idea to follow up this study with a more detailed analysis to account to the variation in the formulation.

```{r, echo=FALSE}

#pander(data.frame(missing.response = sum(is.na(dfmaster$CO))),caption = "Count of data elements redacted due to missing response.")

dfmaster <- dfmaster[!is.na(dfmaster$CO), ]  

dfmaster$experiment.r <- as.factor(dfmaster$experiment)


library(ggplot2)

ggplot(aes(y = CO, x = Formulation), data = dfmaster) + geom_boxplot() +theme(axis.text.x = element_text(angle = 90, hjust = 1)) +ggtitle("CO Levels By Formulation")

ggplot(aes(y = CO, x = labtech), data = dfmaster) + geom_boxplot() +theme(axis.text.x = element_text(angle = 90, hjust = 1)) +ggtitle("CO Levels By Labtech")


ggplot(aes(y=df.counts$count, x=experiment), data = df.counts) +geom_point(size=2, shape=23)+theme(axis.text.x = element_text(angle = 90, hjust = 1)) +ggtitle("Replicates Per Experiment")
```



\newpage

##Analysis Section

### Levene Test for Equality of Variances
\

```{r}
library(car)
#leveneTest(as.vector(scale(CO.n)), experiment.r)
attach(dfmaster)
leveneTest(CO, experiment.r)
```
The Levene test is significant.   The Brown and Forsyth is an alternative test on the variances and we perform that as confirmation.

### Brown and Forsythe Test for equality of variances. 

The Levene test uses spread from the mean to check for variances while the Brown-Forsythe uses deviation from the median. 

```{r}
library(onewaytests)
bf.test(CO ~ experiment.r,data=dfmaster)
```

### ANOVA Test

We perform the standard ANOVA here.  We rejected the hypothesis of constant variance within groups, but ANOVA is fairly roubust to violations of the constant variance assuption.  
```{r}
lm <- lm(CO ~ experiment.r,data = dfmaster)
lm.null <- lm(CO ~1 , data = dfmaster)
anova(lm.null,lm)
```
The p-value is very small so the null hypothesis that there is no effect of experiment on $CO$ level is rejected. 

### Welch Test 

We perform the Welch's Heteroscedastic F Test.  This is an anternative to the ANOVA when the group variances are not equal.  

```{r}

welch.test(CO ~ experiment.r, data=dfmaster, rate = 0, alpha = 0.05, na.rm = TRUE, verbose = TRUE)
```

### Kruskal-Wallis Rank Sum Test 

The tests above have demontstrated that the group variances are not equal and that the group means are not equal. We perform one last test for equality of group means and then seek to find the sotchastic ordering which will guide our selection of the best experimental results. 

```{r}

kruskal.test(CO~experiment.r, data = dfmaster)
```
Again, we have a low p-vaule for the null hypothesis of equal means. 

### Dunn Test

The Dunn test will be the basis for selecting the experiements which performed the best.  This test tell us which groups are dissimilar and which are not. We use the Z values for selecting 

```{r,echo=FALSE, results='hide', message=FALSE, warning=FALSE}
library(dunn.test)
attach(dfmaster)
dt <- dunn.test(CO, experiment.r, method="hs", list=FALSE)

levels.experiment <- levels(dfmaster$experiment.r)

dt.df <- as.data.frame(dt)
dt.df <- dt.df[order(dt.df$Z),]

dt.df.sig <- dt.df[which(dt.df$P.adjusted <0.05),]
pander(dt.df.sig, caption = "Significant Paired Comparisons")

dt.df.z <- dt.df[which(abs(dt.df$Z)>1.96),]
dt.df.z <- dt.df.z [order(dt.df.z$Z),]

dt.df.z.positive <- dt.df.z[dt.df.z$Z>0,]
dt.df.z.positive$promising<-t(data.frame(strsplit(as.character(dt.df.z.positive$comparisons),split=' - '))[1,])

dt.df.z.negative <- dt.df.z[dt.df.z$Z<0,]
dt.df.z.negative$promising<-t(data.frame(strsplit(as.character(dt.df.z.negative$comparisons),split=' - '))[2,])

c.promising <-c(dt.df.z.negative$promising,dt.df.z.positive$promising)
t.promising <-table(c.promising)
dft.t <-data.frame(t.promising)
dft.t <- dft.t[dft.t$Freq>=18,]
dft.t <- dft.t[order(dft.t$Freq),]

```

From the pairwise results we visually inspected the pairwise results for significance and noted several experiments dominated in ranking, but none completey dominated.  There were 820 pairwise comparisons.  We then used the Z-scores to establish a stochastic ordering.  Experiments which dominated 18 or more other experiments are listed below.  

```{r,echo=FALSE}
pander(dft.t, caption = "Most promising experiments")

ggplot(aes(y = CO, x = experiment.r), data = dfmaster) + geom_boxplot() +theme(axis.text.x = element_text(angle = 90, hjust = 1)) +ggtitle("CO Levels By Experiment")

```


```{r,echo=FALSE}
# ### Tuckey HSD
# require(graphics)
# summary(fm1 <- aov(CO.n ~ experiment.r,data = d))
# tkR <-TukeyHSD(fm1, "experiment.r", ordered = TRUE)
# plot(TukeyHSD(fm1, "experiment.r"))
# a1 <-aov(CO.r ~experiment.r)
# posthoc <- TukeyHSD(x=a1, 'experiment.r', conf.level=0.95)
```


\newpage 

##Apendix A VBA Data Extract 

This is the listing of code for the extract of worksheets from excel to csv format. 
```
Private Sub SaveAllSheetsAsCSV()
On Error GoTo Heaven

' each sheet reference
Dim Sheet As Worksheet
' path to output to
Dim OutputPath As String
' name of each csv
Dim OutputFile As String

Application.ScreenUpdating = False
Application.DisplayAlerts = False
Application.EnableEvents = False

' ask the user where to save
OutputPath = InputBox("Enter a directory to save to", "Save to directory", Path)

If OutputPath <> "" Then

    ' save for each sheet
    For Each Sheet In Sheets

        OutputFile = OutputPath & "\" & Sheet.Name & ".csv"

        ' make a copy to create a new book with this sheet
        ' otherwise you will always only get the first sheet
        Sheet.Copy
        ' this copy will now become active
        ActiveWorkbook.SaveAs Filename:=OutputFile, FileFormat:=xlCSV, CreateBackup:=False
        ActiveWorkbook.Close
    Next

End If

Finally:
Application.ScreenUpdating = True
Application.DisplayAlerts = True
Application.EnableEvents = True

Exit Sub

Heaven:
MsgBox "Couldn't save all sheets to CSV." & vbCrLf & _
        "Source: " & Err.Source & " " & vbCrLf & _
        "Number: " & Err.Number & " " & vbCrLf & _
        "Description: " & Err.Description & " " & vbCrLf

GoTo Finally
End Sub


```


##Bibliography











